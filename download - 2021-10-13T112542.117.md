Please enable JavaScript to view this page.

You must be logged in to view this page.

You must be a Lambda School student to view this page.

<a href="#content" id="skippy" class="sr-only sr-only-focusable"></a>

<span class="skiplink-text">Skip to main content</span>

<a href="/" class="navbar-brand"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMyIgaGVpZ2h0PSIzNSIgdmlld2JveD0iMCAwIDMzIDM1IiBmaWxsPSJub25lIj4KICAgICAgICAgICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMCAwVjE2LjA2MDlDMCAyNy43MzM1IDkuMDg5MjkgMzEuNzg0MyAxNS43MzIxIDM0Ljc1MTNIMTUuNzVMMTYuMjg1NyAzNUMxNi40MTA3IDM0LjkyODkgMTYuNTM1NyAzNC44NzU2IDE2LjY3ODYgMzQuODIyM0MxNi43NSAzNC43ODY4IDE2LjgzOTMgMzQuNzUxMyAxNi45MTA3IDM0LjcxNTdDMjMuNTcxNCAzMS43NjY1IDMyLjY5NjQgMjcuNjk4IDMyLjY5NjQgMTYuMDYwOVYwSDBaTTIwLjcwNzEgMjMuNDUzNkwyMC4zNTcxIDIyLjUxMDJMMTUuNjA3MSAxMC4wNzM2QzE1LjMyMTQgMTAuODAyIDE0LjY2MDcgMTIuNTYwOSAxMy45NDY0IDE0LjQ0NDJMMTEuMjE0MyAyMS43ODE3QzExLjA4OTMgMjIuMTM3MSAxMS4xNjA3IDIyLjMxNDcgMTEuMjUgMjIuNDM5MUMxMS40NDY0IDIyLjY3MDEgMTEuODc2OCAyMi42NzAxIDEyLjU1NTQgMjIuNjcwMUgxMi42Nzg2TDEyLjY3NjggMjMuNDUxOEg3LjU2OTY0VjIyLjY3MDFINy45NjI1QzguNjU4OTMgMjIuNjcwMSA5LjIzMDM2IDIyLjM2OCA5LjY1ODkzIDIxLjUxNTJMMTAuMTc2OCAyMC4zNDI2TDE0LjkwODkgOC4yOTY5NkwxNC4wNjk2IDYuMDc2MTRIMTguNDgwNEwyNC41Njk2IDIyLjAxMjdMMjUuMTI1IDIzLjQ1MzZIMjAuNzA3MVoiIGZpbGw9IiNFQzM5NDQiPjwvcGF0aD4KICAgICAgICAgICAgICA8L3N2Zz4=" /></a>

![](data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdib3g9IjAgMCAzMCAzMCIgd2lkdGg9IjMwIiBoZWlnaHQ9IjMwIiBmb2N1c2FibGU9ImZhbHNlIj4KICAgICAgICAgICAgICAgIDx0aXRsZT5NZW51PC90aXRsZT4KICAgICAgICAgICAgICAgIDxwYXRoIHN0cm9rZT0iI2ZmZmZmZiIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1taXRlcmxpbWl0PSIxMCIgZD0iTTQgN2gyMk00IDE1aDIyTTQgMjNoMjIiPjwvcGF0aD4KICAgICAgICAgICAgICA8L3N2Zz4=)

#### Computer Science Legacy

<a href="/cs/sprint/recd4D4w3QrigPqUF" class="bd-toc-link">1.  Intro to Python and OOP</a>

-   [Introduction to Python I](/cs/module/recay2erzDlYUPSeO/)
-   [Introduction to Python II](/cs/module/recwpe3Y9TVWrGT8L/)
-   [Introduction to Python III](/cs/module/reca7NYptklr7F403/)
-   [Introduction to Python IV](/cs/module/recc3eWphKVYd0oHT/)

<a href="/cs/sprint/recR4gHcvD21ziR9a" class="bd-toc-link">2.  Data Structures</a>

-   [Data Structures I](/cs/module/rec3MaMAY78iDm7ax/)
-   [Data Structures II](/cs/module/recMcvOrFw5BWUku3/)
-   [Data Structures III](/cs/module/recx53S3pYfDfvFDm/)
-   [Data Structures IV](/cs/module/recHdwPne4Xt3A7lk/)

<a href="/cs/sprint/recd9grrKlURJ453N" class="bd-toc-link">3.  Algorithms</a>

-   [Iterative Sorting](/cs/module/reck76SPX26beGSqE/)
-   [Recursive Sorting](/cs/module/reccRh9h6ccXghfA4/)
-   [A First-Pass Solution](/cs/module/recrCuZQMVI6LvxhD/)
-   [Writing Better Solutions](/cs/module/recsvJCzPlM2X63ZX/)

<a href="/cs/sprint/recvDjRQEq49uoWsU" class="bd-toc-link">4.  CS Unit 1 Build</a>

<a href="/cs/sprint/recAr3gdL8U57eho1" class="bd-toc-link">5.  Hash Tables</a>

-   [Hash Tables I](/cs/module/recSwIvbSV630gdVk/)
-   [Hash Tables II](/cs/module/recHzCwboKBLBB0Re/)
-   [Hash Tables III & IV](/cs/module/recsEDFseukQWg92c/)

<a href="/cs/sprint/rec7U9K7OCL5ihj0t" class="bd-toc-link">6.  Graphs</a>

-   [Graphs I](/cs/module/recBMbHtb8AOXq3UL/)
-   [Graphs II](/cs/module/recZL2m6Gx7B4dU3G/)
-   [Graphs III](/cs/module/reck4RVWsg82eiYPZ/)
-   [Graphs IV](/cs/module/recoGWlBHjuJxkL1y/)

<a href="/cs/sprint/recndTnO1V8oDbBPb" class="bd-toc-link">7.  Computer Architecture</a>

-   [Computer Architecture: Basics, Number Bases](/cs/module/recsuJbrrFgbFUCRX/)
-   [Computer Architecture: Bitwise Operations](/cs/module/rec2NHr4Eyib7XdED/)
-   [Computer Architecture: The System Stack](/cs/module/recvQUkzz23NTj20G/)
-   [Computer Architecture: Subroutines, CALL/RET](/cs/module/recGPVAdvQcmopSIO/)

<a href="/cs/sprint/reco0t22NdXmr8VyL" class="bd-toc-link">8.  CS Unit 2 Build</a>

------------------------------------------------------------------------

<a href="/" class="navbar-brand"><img src="data:image/svg+xml;base64,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" /></a>

#### Computer Science Legacy

<a href="/cs/sprint/recd4D4w3QrigPqUF" class="bd-toc-link">1.  Intro to Python and OOP</a>

-   [Introduction to Python I](/cs/module/recay2erzDlYUPSeO/)
-   [Introduction to Python II](/cs/module/recwpe3Y9TVWrGT8L/)
-   [Introduction to Python III](/cs/module/reca7NYptklr7F403/)
-   [Introduction to Python IV](/cs/module/recc3eWphKVYd0oHT/)

<a href="/cs/sprint/recR4gHcvD21ziR9a" class="bd-toc-link">2.  Data Structures</a>

-   [Data Structures I](/cs/module/rec3MaMAY78iDm7ax/)
-   [Data Structures II](/cs/module/recMcvOrFw5BWUku3/)
-   [Data Structures III](/cs/module/recx53S3pYfDfvFDm/)
-   [Data Structures IV](/cs/module/recHdwPne4Xt3A7lk/)

<a href="/cs/sprint/recd9grrKlURJ453N" class="bd-toc-link">3.  Algorithms</a>

-   [Iterative Sorting](/cs/module/reck76SPX26beGSqE/)
-   [Recursive Sorting](/cs/module/reccRh9h6ccXghfA4/)
-   [A First-Pass Solution](/cs/module/recrCuZQMVI6LvxhD/)
-   [Writing Better Solutions](/cs/module/recsvJCzPlM2X63ZX/)

<a href="/cs/sprint/recvDjRQEq49uoWsU" class="bd-toc-link">4.  CS Unit 1 Build</a>

<a href="/cs/sprint/recAr3gdL8U57eho1" class="bd-toc-link">5.  Hash Tables</a>

-   [Hash Tables I](/cs/module/recSwIvbSV630gdVk/)
-   [Hash Tables II](/cs/module/recHzCwboKBLBB0Re/)
-   [Hash Tables III & IV](/cs/module/recsEDFseukQWg92c/)

<a href="/cs/sprint/rec7U9K7OCL5ihj0t" class="bd-toc-link">6.  Graphs</a>

-   [Graphs I](/cs/module/recBMbHtb8AOXq3UL/)
-   [Graphs II](/cs/module/recZL2m6Gx7B4dU3G/)
-   [Graphs III](/cs/module/reck4RVWsg82eiYPZ/)
-   [Graphs IV](/cs/module/recoGWlBHjuJxkL1y/)

<a href="/cs/sprint/recndTnO1V8oDbBPb" class="bd-toc-link">7.  Computer Architecture</a>

-   [Computer Architecture: Basics, Number Bases](/cs/module/recsuJbrrFgbFUCRX/)
-   [Computer Architecture: Bitwise Operations](/cs/module/rec2NHr4Eyib7XdED/)
-   [Computer Architecture: The System Stack](/cs/module/recvQUkzz23NTj20G/)
-   [Computer Architecture: Subroutines, CALL/RET](/cs/module/recGPVAdvQcmopSIO/)

<a href="/cs/sprint/reco0t22NdXmr8VyL" class="bd-toc-link">8.  CS Unit 2 Build</a>

------------------------------------------------------------------------

-   [Prepare](#prepare)
-   [Learn](#learn)
-   [Project](#project)
-   [Review](#review)

# Iterative Sorting

<span class="lead"> </span>

**At the end of this module, you should be able to:**

-   define what runtime complexity is, differentiate between various classifications and categorize the performance of an algorithm using Big O notation
-   describe the differences between Linear and Binary Searching algorithms
-   distinguish when to use, classify the performance, and implement code to conduct classic iterative sorting algorithms

#### Pro Tip

Keep in mind that anything you put on social media reflects your brand. Consider what is important for you to say and for other people to hear you say, and use this to shape a social media presence that is both professional and authentic to you.

## <a href="#prepare" id="prepare" class="anchor"><span class="octicon octicon-link"></span></a>Prepare

Review each preclass resource before class.

-   

    # An error occurred.

    [Try watching this video on www.youtube.com](https://www.youtube.com/watch?v=rEx9E_Oq8xg), or enable JavaScript if it is disabled in your browser.

-   

    # An error occurred.

    [Try watching this video on www.youtube.com](https://www.youtube.com/watch?v=a1oLy-ft8o8), or enable JavaScript if it is disabled in your browser.

-   

    # An error occurred.

    [Try watching this video on www.youtube.com](https://www.youtube.com/watch?v=u-CBHEhllHg), or enable JavaScript if it is disabled in your browser.

## <a href="#learn" id="learn" class="anchor"><span class="octicon octicon-link"></span></a>Learn

#### Learn to define what runtime complexity is, differentiate between various classifications and categorize the performance of an algorithm using Big O notation

##### Overview

### What is an algorithm?

An algorithm is a set of instructions for accomplishing a task. Because of this broad definition, we could call every piece of code an algorithm.

### How do we measure how “good” an algorithm is?

After coming up with a first-pass solution to a problem, we need to measure how “good” our solution is. Will it stand up to the test of millions of users? Is it fast enough that our users will be blown away by how quickly they get their results? Or will torturously slow speeds cause lag that drives them all away?

When given a choice between different algorithms, we want to choose the most efficient algorithm (considering both *time* and *space* efficiency depending on our needs).

*Note: It is common for your first solution to work with a few items or users, but break as you add more. Making sure solutions scale is something that all developers must remain vigilant about.*

### What is Big O notation?

We need a way to talk about efficiency (number of operations in the worst case) in a more general sense.

Big O notation is a way of describing the rate of change in the execution speed of an algorithm when the data size increases. It is the agreed-upon terminology we use to describe how long an algorithm takes to run. It is a way of comparing different algorithm’s efficiencies.

The specific terms of Big O notation describe how fast the runtime grows (relative to the size of the input) with a focus on when the input gets extremely large.

Why do we focus on the growth of runtime versus exact runtime? The exact runtime is dependent on the specific computer that is running the algorithm, so we cannot compare efficiencies that way. By focusing on the general growth, we can avoid the differences in exact runtime between machines and environments.

We also talk about runtime relative to the input size because we need to express our speed in terms of *something*. So we show the speed of the algorithm in terms of the input size. That way, we can see how the speed reacts as the input size grows.

We don’t care about speed when the input size is small. The differences in speed are likely to be minimal when the input size is small. When the input size gets enormous, that is where we can see the differences in efficiency between different algorithms.

### Common Big O run times

Refer to the table below to see a list of the most common run times. The table is ordered from fastest to slowest.

![](https://tk-assets.lambdaschool.com/7e05ba4e-0889-4314-9db7-abaedc4e6d36_Untitled.png)

Besides the table, it’s also essential to look at the curves of these different run times.

![](https://tk-assets.lambdaschool.com/e4357b5f-1d63-44cd-b8a0-4957260ae9ec_Untitled1.png)

Again, `n` represents the size of the data, and on the chart above, `N` represents the number of operations. This visualization should help illustrate why `O(1)` or `O(log n)` is the most desirable.

*Note: Big O only matters for large data sets. An `O(n^3)` solution is adequate, as long as you can guarantee that your datasets will always be small.*

### A few examples

Let’s look at a few different examples of Python functions that print something to the output. For each of these, the input will be `items`.

#### Contanst Time `O(1)`

    def print_one_item(items):
        print(items[0])

Why is this constant time? Because no matter how large or small the input is (1,000,000 or 10), the number of computations within the function is the same.

#### Linear Time `O(n)`

    def print_every_item(items):
        for item in items:
            print(item)

Why is this classified as linear time? Because the speed of the algorithms increases at the same rate as the input size. If `items` has ten items, then the function will print ten times. If it has 10,000 items, then the function will print 10,000 times.

#### Quadratic Time `O(n^2)`

    def print_pairs(items):
        for item_one in items:
            for item_two in items:
                print(item_one, item_two)

Why is this quadratic time? The clue is the nested for loops. These nested for loops mean that for each item in `items` (the outer loop), we iterate through every item in `items` (the inner loop). For an input size of `n`, we have to print `n` \* `n` times or `n^2` times.

### What about constants?

What if we had a function like this?

    def do_a_bunch_of_stuff(items):
        last_idx = len(items) - 1
        print(items[last_idx])

        middle_idx = len(items) / 2
        idx = 0
        while idx < middle_idx:
            print(items[idx])
            idx = idx + 1

        for num in range(2000):
            print(num)

`print(items[last_idx])` is constant time because it doesn’t change as the input changes. So, that portion of the function is `O(1)`.

The while loop that prints up to the middle index is 1/2 of whatever the input size is; we can say that portion of the function is `O(n/2)`.

The final portion will run 2000 times, no matter the size of the input.

So, putting it all together, we could say that the efficiency is `O(1 +                   n/2 + 2000)`. However, we don’t say this. We just describe this function as having linear time `O(n)` because we drop all of the constants. Why do we cut all of the constants? Because as the input size gets huge, adding 2000 or dividing by 2 has minimal effect on the performance of the algorithm.

### Most significant term

Let’s consider the following function:

    def do_different_things(items):
        for item in items:
            print(item)

        for item_one in items:
            for item_two in items:
                print(item_one, item_two)

We could describe this function as `O(n + n^2)`; however, we only need to keep the essential term, which is `n^2`, so this would be `O(n^2)`. Why can we do this? Because as the input size (`n`) gets larger and larger, the less significant terms have less of an effect, and only the most significant term is important.

### Big O represents the worst-case

Let’s consider the following function:

    def search_for_thing(items, thing):
        for item in items:
            if item == thing:
                return True

        return False

What would the result be if it just so happens that the `thing` we are looking for in `items` is the very first item in the list? The function would only have to look at one item in `items` before returning. In this case, it would be `O(1)`. But, when we are talking about the complexity of a function, we usually assume the “worst case”. What would the “worst case” be? It would be if it were the last item in `items`. In that case, we would have to look through all the `items`, and that complexity would be `O(n)`.

*Note: When talking about runtime complexity in casual conversation, engineers often blur the distinction between big theta and big O notation. In reality, these are two distinct ways of describing an algorithm. Big theta gives both an upper and a lower bound for the running time. Big O only gives an upper bound. Refer the following articles to dive deeper: [Big-Theta notation](https://www.khanacademy.org/computing/computer-science/algorithms/asymptotic-notation/a/big-big-theta-notation) and [Big-O notation](https://www.khanacademy.org/computing/computer-science/algorithms/asymptotic-notation/a/big-o-notation).*

### Do constants ever matter?

Complexity analysis with Big O notation is a valuable tool, and you should get in the habit of thinking about the efficiency of the algorithms you write and use in your code. However, just because two algorithms have the same Big O notation doesn’t mean they are equal.

Imagine you have a script that takes 1 hour to run. By improving the function, you can divide that runtime by six, and now it only takes 10 minutes to run. With Big O notation, `O(n)` and `O(n/6)` can both be written as `O(n)`, but that doesn’t mean it isn’t worth optimizing the script to save 50 minutes every time the script runs.

That being said, there is a term you should become familiar with: **premature optimization** ([xkcd: Optimization](https://xkcd.com/1691/)). Sometimes, you can sacrifice readability or spend too much time on something to improve its efficiency. Depending on the situation, it could be that having a finished product to iterate on is more important than maximally efficient code. It is your job as a developer to know when spending time making your code more efficient is necessary. You will always be making calculated tradeoffs between runtime, memory, development time, readability, and maintainability. It takes time to develop the wisdom to strike the right balance depending on the scenario.

##### Follow Along

Let’s look at some code snippets that exhibit some runtime classifications we’ll discuss in class.

    def foo(n):
        i = 1
        while i < n:
            print(i)
            i *= 2

First, let’s think about what the above function is doing. It’s printing `i`…but `i` is not being incremented by 1, as we might usually see. It’s *doubled* every time we run the loop. So, for example, if `n = 100`, then the final result would be…

    1
    2
    4
    8
    16
    32
    64

Or if `n = 10`, then we would print…

    1
    2
    4
    8

We can use the process of elimination to narrow down which runtime classification makes sense for this algorithm. The number of times the loop runs seems to vary based on the value of `n`, so this is NOT O(1).

We can also see from the above examples that the number of times the loop runs is increasing *slower* than the size of the input is increasing. `n` must be *doubled* before the loop will run one more time. We can eliminate classifications such as O(n log n), O(n^c), O(c^n), and O(n!).

The only two options left at this point are logarithmic and linear. Since the two rates of growth (input, the number of operations) are not the same, **this function must run in logarithmic time!**

##### Challenge

1.  Classify the run times of each of the following scenarios:

A. You are searching for a specific name in a phone book (that is sorted alphabetically). B. You meet someone, and they give you their phone number. You realize later that you forgot their name! To match their number with a name, you look through a phone book until you find their phone number.

1.  Classify the runtimes of each of the following functions:

A. Problem One

    def foo(n):
        sq_root = int(math.sqrt(n))
        for i in range(0, sq_root):
            print(i)

B. Problem Two

    def bar(x):
        sum = 0
        for i in range(0, 1463):
            i += 1
            for j in range(0, x):
                    for k in range(x, x + 15):
                        sum += 1

C. Problem Three

    def baz(array):
        print(array[1])
        midpoint = len(array) // 2
        for i in range(0, midpoint):
            print(array[i])
        for _ in range(1000):
            print('hi')

1.  Do both of these functions have the same runtime? *(Notice the difference between their inputs)*

A.

    def make_num_pairs(n):
        for num_one in range(n):
            for num_two in range(n):
                print(num_one, num_two)

B.

    def make_item_pairs(items):
        for item_one in items:
            for item_two in items:
                print(item_one, item_two)

------------------------------------------------------------------------

#### Learn to describe the differences between Linear and Binary Searching algorithms

##### Overview

### What is a linear search?

Suppose I am thinking of a number between `1` and `1000`. The object of the game is for you to guess the number I am thinking of with as few guesses as possible. Every time you make a guess, I will tell you your guess is either:

-   “Too high.”
-   “Too low.”
-   “Correct.”

What strategy for guessing would you choose? One strategy is to start with `1` and increase your guess by `1` every time. Eventually, you are guaranteed to make a correct guess. However, imagine that I picked `1000`. It would take you `1000` guesses (the maximum number given this strategy). Given this, this strategy doesn’t seem like it’s the best one out there.

Another way to think about this technique and to see why it’s not so great is that you can only eliminate one number with each subsequent guess. Can you think of a strategy that would eliminate (on average) the highest number of possibilities with each guess?

It’s important to realize that with the number guessing game, the analogy is for a *sorted* list of elements. There are times where a linear approach is the only way to go. For example, if the guessing game was modified so that I only answered “Correct” or “Incorrect” after each guess, then the best strategy would be to start at 1 and increment each guess by 1.

Another example where linear search would be required is imagine that you have a collection of ticket stubs that were collected at the door of a theater. You want to know if the person who purchased seat F16 showed up for the performance. The only way to find out (if the collection of stubs is unsorted), is to check each ticket stub, one at a time, and to check every one of them.

### Binary search

Were you able to think of a better strategy? The best strategy is to eliminate half of the numbers with each guess. We do that by guessing the middle number each time. Because after each guess you find out if your guess was too low or too high, you can determine which half of the possibilities you can throw out.

To understand why the middle is the best guess (on average), let’s consider the possibility that I picked `800`. By guessing the middle number `500`, you eliminate five hundred guesses. You might think, but I could’ve guessed `750` and eliminated `750` numbers, thus getting even closer to the correct answer much quicker. However, consider the alternate scenario where I picked `200`. When you guess `750` this time, you are actually further away from the correct guess and can only eliminate two hundred and fifty possibilities. Thus, on average, you will eliminate the most possibilities by guessing the middle each time.

So, again, continuing with the number guessing game, instead of starting with `1` and incrementing your guess by `1` each time, this time you start with a pick of `500`. Because I picked `1000`, I now tell you, “Too low.” Because you know `500` is too low, you eliminate `1-500` from the possibilities. You now know that the possible guesses are `501-1000`. You need to choose the middle again, so you choose `750`. Again, I say, “Too low.” You get rid of `501-750` and `751-1000` remain. Your next middle pick is `876` and again I say, “Too low.” Your next middle pick is `938` and again I say, “Too low.” The rest of your picks are summarized below:

-   `969`. “Too low.”
-   `985`. “Too low.”
-   `993`. “Too low.”
-   `997`. “Too low.”
-   `999`. “Too low.”
-   `1000` “Correct.”

If we count up the number of guesses we took, we get `10`. If we used the simple linear search method, it would have taken us `1000` guesses.

![](https://tk-assets.lambdaschool.com/9544e798-7291-4b34-9f6f-2f999c4ab86a_Algorithms-Guessing-Game-Animation.gif)

*Note: A reminder that this binary search method **only works if the data is already sorted**.*

### Logarithms

This situation where I’m halving the number of possibilities each time, mathematically, is considered a logarithm. You probably forgot what a logarithm is if it has been a while since you studied math. However, most of you haven’t forgotten what an exponent is. We will approach our understanding of logarithms by understanding inverse relationships.

*Note: for a quick refresher on logarithms, see [Intro to logarithms on Khan Academy](https://youtu.be/Z5myJ8dg_rM). For exponents, see [Intro to exponents on Khan Academy](https://youtu.be/XZRQhkii0h0)*

Logarithms and exponents are related to each other in the same way that multiplication and division are related to each other. They have an inverse relationship. For example `8                   * 2 = 16`. The inverse of this would be `16 / 2 = 8` or `16 / 8 = 2`. Basically, you can use division to undo what you did with multiplication.

It’s the same with exponents and logarithms. When we have `10^2 =                   100` , we are saying `10` multiplied by *itself* `2` times equals `100`. The inverse would be `log10(100) = 2`, or how many `10`s would we have to multiply to equal `100`. The answer is `2`.

Now we’ve been talking about halving numbers each time. This is `log2(n)`. Just like if we double numbers each time it’s `n^2`. Whenever we talk about logarithms in relation to describing the runtime of an algorithm, we are talking about `log2(n)`.

When we talk about logarithms in computing, we almost always mean `log2()`. The reason for this is that computers operate on binary or a base 2 number system.

##### Follow Along

Now, let’s write a binary search function in Python. We will write our function to expect a ***sorted*** list of integers. If the item we are searching for is in the list, then we will return the position that it holds in the list.

    def binary_search(my_list):
        pass

Now, when we first get the list, we need to set two different pointers. The first pointer `low`, will point to the first item in the list. The second pointer `high`, will point to the last item in the list.

    def binary_search(my_list):
        low = 0
        high = len(my_list) - 1

Now, we need to set up a loop that will continue while the `low` pointer is less than or equal to the `high` pointer.

    def binary_search(my_list):
        low = 0
        high = len(my_list) - 1

        while low <= high:
            pass

The very first thing we need to do each loop is to get the middle index. We do that by averaging the `low` pointer and `high` pointer (rounding down). We do that by adding the `low` pointer to the `high` pointer and dividing by `2` (using the floor division operator `//`).

    def binary_search(my_list):
        low = 0
        high = len(my_list) - 1

        while low <= high:
            middle = (low + high) // 2
                    pass

Now, we need to use that middle index to retrieve the item with that index from our list.

    def binary_search(my_list):
        low = 0
        high = len(my_list) - 1

        while low <= high:
            middle = (low + high) // 2
                    guess = my_list[middle]

Remember that now that we have our guess, there are three options.

1.  Our guess is correct
2.  Our guess is too high
3.  Our guess is too low

We can set up that logic using if statements:

    def binary_search(my_list, search_item):
        low = 0
        high = len(my_list) - 1

        while low <= high:
            middle = (low + high) // 2
                    guess = my_list[middle]
            if guess == search_item:
                pass
            if guess > search_item:
                pass
            else:
                pass

So, now we have our logic set up but we still need to write what happens for each statement. Well, if our `guess` is equal to `search_item`, that means that the `middle` index is the correct index and we need to return that index.

    def binary_search(my_list, search_item):
        low = 0
        high = len(my_list) - 1

        while low <= high:
            middle = (low + high) // 2
                    guess = my_list[middle]
            if guess == search_item:
                return middle
            if guess > search_item:
                pass
            else:
                pass

If our `guess` is too high (greater than our `search_item`), then we need to change our `high` pointer so we reduce our list of possibilities by 1/2. Every index at or above the current `middle` value cannot be the correct answer. Therefore, we need to change our `high` pointer to the index directly below the current `middle` value.

    def binary_search(my_list, search_item):
        low = 0
        high = len(my_list) - 1

        while low <= high:
            middle = (low + high) // 2
                    guess = my_list[middle]
            if guess == search_item:
                return middle
            if guess > search_item:
                high = middle - 1
            else:
                pass

The last possibility is that our guess was too low. Similar to the previous logic, all indices at or below the middle cannot be correct. Therefore, we need to change our `low` pointer to be equal to the index directly after the current `middle` index.

    def binary_search(my_list, search_item):
        low = 0
        high = len(my_list) - 1

        while low <= high:
            middle = (low + high) // 2
                    guess = my_list[middle]
            if guess == search_item:
                return middle
            if guess > search_item:
                high = middle - 1
            else:
                low = middle + 1

This takes care of all the cases where the `search_item` exists in the `my_list` that is passed in. What about if `my_list` does not contain the `search_item`? In that case, we will terminate the while loop without returning from the function. When that happens, we should return the `None` value, which will tell the user of the function that the `search_item` was not found in the list that was passed in.

    def binary_search(my_list, search_item):
        low = 0
        high = len(my_list) - 1

        while low <= high:
            middle = (low + high) // 2
                    guess = my_list[middle]
            if guess == search_item:
                return middle
            if guess > search_item:
                high = middle - 1
            else:
                low = middle + 1
        return None

Let’s test it out by copying the function definition into a Python interpreter and then using it on some test data.

    >>> def binary_search(my_list, search_item):
    ...     low = 0
    ...     high = len(my_list) - 1
    ...     while low <= high:
    ...         middle = (low + high) // 2
    ...         guess = my_list[middle]
    ...         if guess == search_item:
    ...             return middle
    ...         if guess > search_item:
    ...             high = middle - 1
    ...         else:
    ...             low = middle + 1
    ...     return None
    ...
    >>> test_list = [2,4,7,8,9,10,12,34,45]
    >>> binary_search(test_list, 7)
    2
    >>> binary_search(test_list, 34)
    7
    >>>

It looks like we have a working `binary_search` function that we coded in Python.

##### Challenge

1.  Suppose your app has 16,384 users that are stored in a database (the users are sorted alphabetically). Your app needs to search for a specific user and you use binary search. What’s the maximum number of steps it would take? *(Hint: using the logarithm operation is key.)*
2.  Time passes and now your app has *exactly double* the number of users. What’s the maximum number of steps now?
3.  Try writing a Python function to perform a ***linear search*** on a set of data.
4.  Try writing your own Python function to perform a ***binary search*** on a set of data. This will help you remember and internalize this algorithm much better *if you do not refer to our example above* in the process of writing your own. Make sure to use **UPER** as you approach this problem.
5.  Can you rewrite your binary search function so it uses *recursion*?

------------------------------------------------------------------------

#### Learn to distinguish when to use, classify the performance, and implement code to conduct classic iterative sorting algorithms

##### Overview

Sorting is a common thing that we encounter in our everyday lives. When we need to sort something, each of us chooses a strategy without even thinking about it.

Sorting is actually quite practical as well. Upon reflection, it becomes clear that most times things are sorted, it is in order to make searching and finding a specific item easier. Think of how much easier it is to find a book in a library due to the sorting system that is followed. *(For an interesting counterexample, here is an [article](https://classic.qz.com/perfect-company-2/1172282/this-company-built-one-of-the-worlds-most-efficient-warehouses-by-embracing-chaos/) about the efficiency of randomness in Amazon warehouses.)*

### Selection Sort

#### Out-of-place selection sort

Let’s talk about an actual example. Imagine for a moment that you have a shelf of books and you would like your books to be sorted on the shelf alphabetically by title. *How would you go about doing so?*

The most natural way is to scan the books from left to right, looking for the book with the “lowest” alphabetical title (following the standard alphabetical “ABC” order).

![](https://tk-assets.lambdaschool.com/b72646a0-7d67-43be-8874-8760b99313fb_selection-sort-1.gif)f

Here, “Animal Farm” is the “lowest” and should go first in our sorted collection. Therefore, we take that book from the shelf and place it all the way to the left as part of a new “collection of books”.

![](https://tk-assets.lambdaschool.com/0bd1e037-2449-47d5-aa22-f5ea88a7da1f_S2-Illustrations.0011.jpeg)g

Now, we go through the original collection again, looking for the next book that has the “lowest” alphabetical title. When we find it (“Charlotte’s Web” in this case), we place that book in our new collection on the left. Notice that as we go through the original collection, we have to keep track of which book is the lowest. That way, when we get to the end of the collection, we can go back and move that book to the new sorted collection.

![](https://tk-assets.lambdaschool.com/b5352159-aa59-4c20-b1bc-bf6c7241921a_S2-Illustrations.gif)f

We continue repeating this process until the original collection is empty. Notice that the new collection on the left is sorted alphabetically.

![](https://media.giphy.com/media/eNMIt2vUzTKYJD09YF/giphy.gif)f

#### In-place selection sort

The example that we went over above is called an “out-of-place” selection sort. This worked because we had so much extra room on our shelf. But, what if you are trying to sort books and there is no extra room on our shelf? For that, we need to sort our books “in-place”. That means instead of starting a new collection of books, we need to swap books as we encounter them.

![](https://tk-assets.lambdaschool.com/08d41ea3-5422-4289-8e1e-8da7180e519e_S2-Illustrationsasdfasdf.gif)f

So, we start by looking through each book from left to right, keeping track of the lowest book we find. Once we find it, “Animal Farm” in this case, we swap the lowest book with the first position. Now the first position has the lowest book. Next, we repeat this whole process but we start at the second position and will swap the lowest book with the second position when we find it.

![](https://tk-assets.lambdaschool.com/ba68d1c7-9081-4aea-a686-d71e6e10f275_S2-Illustrationssdfasdfasdfasdf.gif)f

During this loop, the book in the second position is already the “lowest” book and so no swapping takes place.

Again, we repeat the process starting now at the third position. Each time we loop through we increment our starting position by 1 until we get to the last position in the collection.

![](https://media.giphy.com/media/QZtI5sqgFco9rXQ8Vi/giphy.gif)f

You can see that once we get to the last position in the collection, our collection is sorted. This was an “in-place” selection sort.

### Insertion Sort

We will now look at another method for sorting a collection of items. This method is called **Insertion Sort**.

Insertion sort is an efficient algorithm for sorting ***small amounts*** of data. Insertion sort can be understood when you think about how most people sort a hand of playing cards.

When you sort cards, you start with an empty left hand and then take one card at a time from a pile of cards that is face down on the table. With each card you pick up from the table, you insert it into the correct position in the left hand. To do so, you compare the current card to each card already in the left hand, starting at the rightmost card. If the current card is smaller, you swap positions. You keep doing this while the current card is smaller than the card on the left. Once the current card is not smaller than the card on the left, you can stop and then pick up a new card.

![](https://media.giphy.com/media/jV0eGw64WOWDExAokV/giphy.gif)f

#### Complexity Analysis

Insertion sort runs in `O(n)` time in it’s best case (already sorted), and `O(n^2)` in its worst and average cases.

If the collection is already sorted, the insertion sort algorithm will still have to go through each item in the collection to make sure it is in the correct position.

The worst case would be if the collection was sorted in decreasing order. This would require us to do the maximum number of iterations to shift items to the right and will be `O(n^2)`.

For the average case, the number of inner loops will not be the maximum but since constants don’t matter, it will still be `O(n^2)`.

### Bubble Sort

Bubble sort is one of the simplest sorting algorithms. It is also very inefficient. This algorithm is often one of the first ones that students learn because it is so simple and intuitive.

The Bubble Sort algorithm can be described in the following terms:

1.  Compare the first and second item of a collection. If the first item is bigger than the second item, swap the items.
2.  Move to the next item. Now, we will compare the second item with the third item. If the second item is bigger than the third, swap the items.
3.  Do this for every item until the end of the list.
4.  Repeat steps 1-3 (decrementing “the end of the list” by 1 each time).

To see a simple example, we will again look at how we would sort some playing cards.

![](https://tk-assets.lambdaschool.com/916f17c0-5160-47f2-bf75-5e7eb1fa2321_Algorithms-Bubble-Sort-Animation.gif)

Notice how in each subsequent pass, the largest item “bubbles up” to become the last item.

#### Complexity Analysis

Even if the list is already sorted, we still have to touch every item in the list. That means that the best case has an `O(n)` runtime complexity (where only the outer loop runs). In the worst case, the inner loop has to perform `1/2 *                   n` operations due to swapping every element. Remembering that we drop the constants in Big O notation, this means that the entire algorithm’s complexity (inner loop and outer loop) can be represented in Big O with `O(n * n)` or `O(n^2)`.

##### Follow Along

### Writing our code for Selection Sort

Now, that we’ve gone through non-code examples for three different classic iterative sorting algorithms, let’s see what a selection sort looks like with actual Python code.

Let’s say we have a collection of integers that are unsorted and we need to sort them (using an “in-place” selection sort).

    our_numbers = [5,9,3,6,2,1,7,8,4]

Let’s define our `selection_sort` function:

    def selection_sort(items):
        # Outer Loop
        for i in range(0, len(items) - 1):
            cur_index = i
            smallest_index = cur_index
            for j in range(cur_index + 1, len(items)):
                if items[j] < items[smallest_index]:
                    smallest_index = j

            items[smallest_index], items[cur_index] = items[cur_index], items[smallest_index]

        return items

The code above follows the same logic that we followed when we were sorting our books “in-place”.

We start by setting up our outer loop with `for i in range(0, len(items)                   - 1):`. This is the loop that says we will go through each item in our collection, one at a time.

Next we define what we do for each item in the collection. Remember with the books we had to go through each book to the right of the current book and keep track of the book with the “lowest” title. To do that in our code, we need to loop through all the items that come after the current index to find the one with the lowest value. We do this with another for loop. With each item, we check if it is smaller than the current smallest and replace the smallest index if so. At the end, before we increment our outer loop, we swap the item that is located in the current index with the smallest item that we located during our loop.

Let’s run our code in the terminal and make sure it works.

    >>> def selection_sort(items):
    ...     # Outer Loop
    ...     for i in range(0, len(items) - 1):
    ...         cur_index = i
    ...         smallest_index = cur_index
    ...         for j in range(cur_index + 1, len(items)):
    ...             if items[j] < items[smallest_index]:
    ...                 smallest_index = j
    ...         items[smallest_index], items[cur_index] = items[cur_index], items[smallest_index]
    ...     return items
    ...
    >>> our_numbers = [5, 9, 3, 6, 2, 1, 7, 8, 4]
    >>> print(selection_sort(our_numbers))
    [1, 2, 3, 4, 5, 6, 7, 8, 9]
    >>>

### Runtime Complexity

When you look at our algorithm, you’ll notice that we have an outer loop that has to go through each of the items in our data. That means, that the big O of the outer loop is `O(n)`. But, we also have an inner loop. Now, with the inner loop we don’t have to check all `n` elements each time. Each time the outer loop increments, our inner loop decreases by 1. On average, we check a list that has 1/2 x `n` elements. This means that the runtime for the algorithm could be represented as `O(n x 1/2 x n)`. But, in big O, we can often ignore the constants. The constants don’t have enough of an effect on the shape of the curve on the graph. So, the true big O of this algorithm is `O(n x n)` which is `O(n^2)`.

Selection sort is a neat algorithm that is very intuitive and can work well for tiny data sets, but it is a very inefficient way to sort data.

##### Challenge

1.  What will the contents of the array that is shown below look like after each pass of the ***Selection Sort*** algorithm?

    ![](https://tk-assets.lambdaschool.com/37acef2d-38c3-4479-a7db-582fa68943e1_Resources23.png)

2.  Define your own function that sorts the data “out-of-place” and mirrors the process we used for our “out-of-place” book sorting example. Compare this “out-of-place” selection sort to the “in-place” function that we defined together. What is different about it? Which version do you think is better and why?

3.  What will the contents of the *same* array look like after each pass of the ***Insertion Sort*** algorithm?

    ![](https://tk-assets.lambdaschool.com/37acef2d-38c3-4479-a7db-582fa68943e1_Resources23.png)

4.  You have the cards 2, 7, 3, 4, and 6. Write an algorithm in pseudo-code that arranges the cards in ascending order.

5.  What will the contents of the array below look like after each pass of the ***Bubble Sort*** algorithm?

    ![](https://tk-assets.lambdaschool.com/37acef2d-38c3-4479-a7db-582fa68943e1_Resources23.png)

6.  What would the following array look like after ***one iteration*** of Bubble Sort?

         my_arr = [3,6,4,12,11,15,1,2]

------------------------------------------------------------------------

## <a href="#project" id="project" class="anchor"><span class="octicon octicon-link"></span></a>Project

-   ##### [Iterative Sorting](https://github.com/LambdaSchool/cs-module-project-iterative-sorting)

## <a href="#review" id="review" class="anchor"><span class="octicon octicon-link"></span></a>Review

### Class Recordings

You can use class recordings to help you master the material.

-   **[Iterative Sorting for CS35 w/ Sean Chen](https://youtu.be/fQzbIWow1SY)**

    Student should be able to define what runtime complexity is, differentiate between various classifications and categorize the performance of an algorithm using Big O notation

-   [All previous recordings](/archive/CS/module/reck76SPX26beGSqE)

### Demonstrate Mastery

To demonstrate mastery of this module, you need to complete and pass a code review on each of the following:

-   Objective challenge:

    1.  Classify the run times of each of the following scenarios:

    A. You are searching for a specific name in a phone book (that is sorted alphabetically). B. You meet someone, and they give you their phone number. You realize later that you forgot their name! To match their number with a name, you look through a phone book until you find their phone number.

    1.  Classify the runtimes of each of the following functions:

    A. Problem One

        def foo(n):
            sq_root = int(math.sqrt(n))
            for i in range(0, sq_root):
                print(i)

    B. Problem Two

        def bar(x):
            sum = 0
            for i in range(0, 1463):
                i += 1
                for j in range(0, x):
                        for k in range(x, x + 15):
                            sum += 1

    C. Problem Three

        def baz(array):
            print(array[1])
            midpoint = len(array) // 2
            for i in range(0, midpoint):
                print(array[i])
            for _ in range(1000):
                print('hi')

    1.  Do both of these functions have the same runtime? *(Notice the difference between their inputs)*

    A.

        def make_num_pairs(n):
            for num_one in range(n):
                for num_two in range(n):
                    print(num_one, num_two)

    B.

        def make_item_pairs(items):
            for item_one in items:
                for item_two in items:
                    print(item_one, item_two)

-   Objective challenge:
    1.  Suppose your app has 16,384 users that are stored in a database (the users are sorted alphabetically). Your app needs to search for a specific user and you use binary search. What’s the maximum number of steps it would take? *(Hint: using the logarithm operation is key.)*
    2.  Time passes and now your app has *exactly double* the number of users. What’s the maximum number of steps now?
    3.  Try writing a Python function to perform a ***linear search*** on a set of data.
    4.  Try writing your own Python function to perform a ***binary search*** on a set of data. This will help you remember and internalize this algorithm much better *if you do not refer to our example above* in the process of writing your own. Make sure to use **UPER** as you approach this problem.
    5.  Can you rewrite your binary search function so it uses *recursion*?

-   Objective challenge:
    1.  What will the contents of the array that is shown below look like after each pass of the ***Selection Sort*** algorithm?

        ![](https://tk-assets.lambdaschool.com/37acef2d-38c3-4479-a7db-582fa68943e1_Resources23.png)

    2.  Define your own function that sorts the data “out-of-place” and mirrors the process we used for our “out-of-place” book sorting example. Compare this “out-of-place” selection sort to the “in-place” function that we defined together. What is different about it? Which version do you think is better and why?

    3.  What will the contents of the *same* array look like after each pass of the ***Insertion Sort*** algorithm?

        ![](https://tk-assets.lambdaschool.com/37acef2d-38c3-4479-a7db-582fa68943e1_Resources23.png)

    4.  You have the cards 2, 7, 3, 4, and 6. Write an algorithm in pseudo-code that arranges the cards in ascending order.

    5.  What will the contents of the array below look like after each pass of the ***Bubble Sort*** algorithm?

        ![](https://tk-assets.lambdaschool.com/37acef2d-38c3-4479-a7db-582fa68943e1_Resources23.png)

    6.  What would the following array look like after ***one iteration*** of Bubble Sort?

             my_arr = [3,6,4,12,11,15,1,2]

-   Project: Iterative Sorting
